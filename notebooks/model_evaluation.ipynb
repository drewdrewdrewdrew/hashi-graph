{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashi Graph Model Evaluation Notebook\n",
    "\n",
    "This notebook provides comprehensive evaluation of trained Hashi graph models, including:\n",
    "- Model loading and inference on validation/test sets\n",
    "- Error analysis and classification\n",
    "- Visual comparison of predicted vs actual puzzles\n",
    "- Error patterns by node attributes\n",
    "- Model interpretability features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import project modules\n",
    "from data import HashiDataset, custom_collate_with_conflicts\n",
    "from models import GCNEdgeClassifier, GATEdgeClassifier, GINEEdgeClassifier, TransformerEdgeClassifier\n",
    "from bridges_gen import generate_bridges\n",
    "from bridges_utils import convert_to_hashi_format\n",
    "from graph_utils import puzzle_to_graph\n",
    "from train_utils import calculate_batch_perfect_puzzles, get_edge_batch_indices\n",
    "from evaluation_utils import (classify_puzzle_error_types, plot_error_heatmap,\n",
    "                              plot_capacity_error_analysis, analyze_error_patterns_by_position,\n",
    "                              create_model_comparison_summary)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Enable autoreload for development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - MODIFY THESE PATHS\n",
    "MODEL_PATH = \"../models/best_model_20241220_120000.pt\"  # Path to saved model\n",
    "CONFIG_PATH = \"../configs/base_config.yaml\"  # Path to config used for training\n",
    "DATA_ROOT = \"../data\"  # Path to dataset root\n",
    "SPLIT = \"val\"  # 'val' or 'test'\n",
    "LIMIT = None  # Limit number of puzzles (None for all)\n",
    "\n",
    "# Analysis settings\n",
    "SAVE_PLOTS = True\n",
    "PLOT_DIR = \"../plots\"\n",
    "if SAVE_PLOTS:\n",
    "    Path(PLOT_DIR).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load configuration from YAML file.\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def get_device() -> torch.device:\n",
    "    \"\"\"Get the best available device.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "def load_model(config: Dict[str, Any], device: torch.device) -> nn.Module:\n",
    "    \"\"\"Load and initialize the model from config.\"\"\"\n",
    "    model_config = config['model']\n",
    "    model_type = model_config.get('type', 'gcn').lower()\n",
    "    \n",
    "    # Get model feature settings\n",
    "    use_capacity = model_config.get('use_capacity', True)\n",
    "    use_structural_degree = model_config.get('use_structural_degree', True)\n",
    use_structural_degree_nsew = model_config.get('use_structural_degree_nsew', False)\n",
    "    use_unused_capacity = model_config.get('use_unused_capacity', True)\n",
    "    use_conflict_status = model_config.get('use_conflict_status', True)\n",
    "    use_global_meta_node = model_config.get('use_global_meta_node', False)\n",
    "    use_row_col_meta = model_config.get('use_row_col_meta', False)\n",
    "    use_closeness_centrality = model_config.get('use_closeness_centrality', False)\n",
    "    \n",
    "    # Determine edge dimension\n",
    "    edge_dim = 3  # base: [inv_dx, inv_dy, is_meta]\n",
    "    if model_config.get('use_conflict_edges', False):\n",
    "        edge_dim += 1\n",
    "    if model_config.get('use_meta_mesh', False):\n",
    "        edge_dim += 1\n",
    "    if model_config.get('use_meta_row_col_edges', False):\n",
    "        edge_dim += 1\n",
    "    if model_config.get('use_edge_labels_as_features', False):\n",
    "        edge_dim += 2\n",
    "    \n",
    "    # Initialize model\n",
    "    if model_type == 'gcn':\n",
    "        model = GCNEdgeClassifier(\n",
    "            node_embedding_dim=model_config['node_embedding_dim'],\n",
    "            hidden_channels=model_config['hidden_channels'],\n",
    "            num_layers=model_config['num_layers'],\n",
    "            dropout=model_config.get('dropout', 0.25),\n",
    "            use_capacity=use_capacity,\n",
    "            use_structural_degree=use_structural_degree,\n",
    "            use_structural_degree_nsew=use_structural_degree_nsew,\n",
    "            use_unused_capacity=use_unused_capacity,\n",
    "            use_conflict_status=use_conflict_status,\n",
    "            use_meta_node=use_global_meta_node,\n",
    "            use_closeness=use_closeness_centrality\n",
    "        )\n",
    "    elif model_type == 'gat':\n",
    "        model = GATEdgeClassifier(\n",
    "            node_embedding_dim=model_config['node_embedding_dim'],\n",
    "            hidden_channels=model_config['hidden_channels'],\n",
    "            num_layers=model_config['num_layers'],\n",
    "            heads=model_config.get('heads', 8),\n",
    "            dropout=model_config.get('dropout', 0.25),\n",
    "            use_capacity=use_capacity,\n",
    "            use_structural_degree=use_structural_degree,\n",
    "            use_structural_degree_nsew=use_structural_degree_nsew,\n",
    "            use_unused_capacity=use_unused_capacity,\n",
    "            use_conflict_status=use_conflict_status,\n",
    "            use_meta_node=use_global_meta_node,\n",
    "            use_row_col_meta=use_row_col_meta,\n",
    "            edge_dim=edge_dim,\n",
    "            use_closeness=use_closeness_centrality\n",
    "        )\n",
    "    elif model_type == 'gine':\n",
    "        model = GINEEdgeClassifier(\n",
    "            node_embedding_dim=model_config['node_embedding_dim'],\n",
    "            hidden_channels=model_config['hidden_channels'],\n",
    "            num_layers=model_config['num_layers'],\n",
    "            dropout=model_config.get('dropout', 0.25),\n",
    "            use_capacity=use_capacity,\n",
    "            use_structural_degree=use_structural_degree,\n",
    "            use_structural_degree_nsew=use_structural_degree_nsew,\n",
    "            use_unused_capacity=use_unused_capacity,\n",
    "            use_conflict_status=use_conflict_status,\n",
    "            use_meta_node=use_global_meta_node,\n",
    "            use_row_col_meta=use_row_col_meta,\n",
    "            edge_dim=edge_dim,\n",
    "            use_closeness=use_closeness_centrality\n",
    "        )\n",
    "    elif model_type == 'transformer':\n",
    "        model = TransformerEdgeClassifier(\n",
    "            node_embedding_dim=model_config['node_embedding_dim'],\n",
    "            hidden_channels=model_config['hidden_channels'],\n",
    "            num_layers=model_config['num_layers'],\n",
    "            heads=model_config.get('heads', 4),\n",
    "            dropout=model_config.get('dropout', 0.25),\n",
    "            use_capacity=use_capacity,\n",
    "            use_structural_degree=use_structural_degree,\n",
    "            use_structural_degree_nsew=use_structural_degree_nsew,\n",
    "            use_unused_capacity=use_unused_capacity,\n",
    "            use_conflict_status=use_conflict_status,\n",
    "            use_meta_node=use_global_meta_node,\n",
    "            use_row_col_meta=use_row_col_meta,\n",
    "            edge_dim=edge_dim,\n",
    "            use_closeness=use_closeness_centrality,\n",
    "            use_verification_head=model_config.get('use_verification_head', False),\n",
    "            verifier_use_puzzle_nodes=model_config.get('verifier_use_puzzle_nodes', False),\n",
    "            verifier_use_row_col_meta_nodes=model_config.get('verifier_use_row_col_meta_nodes', False),\n",
    "            edge_concat_global_meta=model_config.get('edge_concat_global_meta', False)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Load state dict\n",
    "    state_dict = torch.load(MODEL_PATH, map_location=device, weights_only=True)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Load everything\n",
    "print(\"Loading configuration...\")\n",
    "config = load_config(CONFIG_PATH)\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = load_model(config, device)\n",
    "print(f\"Loaded {config['model']['type']} model\")\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "data_config = config['data']\n",
    "model_config = config['model']\n",
    "\n",
    "# Get dataset parameters from config\n",
    "dataset_params = {\n",
    "    'use_degree': model_config.get('use_degree', False),\n",
    "    'use_meta_node': model_config.get('use_global_meta_node', False),\n",
    "    'use_row_col_meta': model_config.get('use_row_col_meta', False),\n",
    "    'use_meta_mesh': model_config.get('use_meta_mesh', False),\n",
    "    'use_meta_row_col_edges': model_config.get('use_meta_row_col_edges', False),\n",
    "    'use_distance': model_config.get('use_distance', True),\n",
    "    'use_edge_labels_as_features': model_config.get('use_edge_labels_as_features', False),\n",
    "    'use_closeness_centrality': model_config.get('use_closeness_centrality', False),\n",
    "    'use_conflict_edges': model_config.get('use_conflict_edges', False),\n",
    "    'use_capacity': model_config.get('use_capacity', True),\n",
    "    'use_structural_degree': model_config.get('use_structural_degree', True),\n",
    "    'use_structural_degree_nsew': model_config.get('use_structural_degree_nsew', False),\n",
    "    'use_unused_capacity': model_config.get('use_unused_capacity', True),\n",
    "    'use_conflict_status': model_config.get('use_conflict_status', True),\n",
    "}\n",
    "\n",
    "dataset = HashiDataset(\n",
    "    root=DATA_ROOT,\n",
    "    split=SPLIT,\n",
    "    size=data_config.get('size'),\n",
    "    difficulty=data_config.get('difficulty'),\n",
    "    limit=LIMIT,\n",
    "    **dataset_params\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,  # Process one puzzle at a time for detailed analysis\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=custom_collate_with_conflicts\n",
    ")\n",
    "\n",
    "print(f\"Loaded {len(dataset)} puzzles for evaluation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}